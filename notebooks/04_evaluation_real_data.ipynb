{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Setup\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.query_parser.parser import QueryParser\n",
    "from src.property_analysis.text_analyzer import PropertyTextAnalyzer\n",
    "from src.property_analysis.schemas import QueryRequirement\n",
    "\n",
    "# Cargar datos\n",
    "data_dir = Path(\"../data/raw\")\n",
    "all_properties = []\n",
    "for json_file in data_dir.glob(\"fotocasa_*.json\"):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        all_properties.extend(data['properties'])\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {len(all_properties)} properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08caea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Queries de prueba\n",
    "test_queries = [\n",
    "    \"Local con entrada independiente\",\n",
    "    \"Piso luminoso con terraza\",\n",
    "    \"Local comercial Barcelona\",\n",
    "    \"Vivienda 3 habitaciones\",\n",
    "    \"Local con parking incluido\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ” Test Queries:\")\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Analizar todas las propiedades (1 vez)\n",
    "analyzer = PropertyTextAnalyzer(backend=\"api\")\n",
    "\n",
    "print(\"ðŸ” Analyzing all properties...\")\n",
    "analyses = analyzer.analyze_batch(all_properties[:50], generate_embeddings=True)\n",
    "print(f\"âœ… Analyzed {len(analyses)} properties\")\n",
    "\n",
    "# Guardar para reutilizar\n",
    "import pickle\n",
    "with open('../data/cache/analyses.pkl', 'wb') as f:\n",
    "    pickle.dump(analyses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Cargar analyses (si ya las tienes)\n",
    "import pickle\n",
    "with open('../data/cache/analyses.pkl', 'rb') as f:\n",
    "    analyses = pickle.load(f)\n",
    "print(f\"âœ… Loaded {len(analyses)} analyses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41908e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Evaluar cada query\n",
    "results_by_query = {}\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    matches = []\n",
    "    for analysis in analyses:\n",
    "        match = analyzer.match_against_query(analysis, query)\n",
    "        matches.append(match)\n",
    "    \n",
    "    # Ordenar\n",
    "    matches.sort(key=lambda m: m.final_score, reverse=True)\n",
    "    \n",
    "    # Top 5\n",
    "    print(f\"\\nTop 5 matches:\")\n",
    "    for i, match in enumerate(matches[:5], 1):\n",
    "        prop = next(p for p in all_properties if p['id'] == match.property_id)\n",
    "        print(f\"\\n{i}. {prop['id']} - Score: {match.final_score:.2f}\")\n",
    "        print(f\"   {prop['location']} | {prop['price']:,}â‚¬\")\n",
    "        print(f\"   Matched features: {len(match.matched_features)}\")\n",
    "    \n",
    "    results_by_query[query] = matches\n",
    "\n",
    "print(\"\\nâœ… Evaluation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: VisualizaciÃ³n de scores\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (query, matches) in enumerate(results_by_query.items()):\n",
    "    scores = [m.final_score for m in matches]\n",
    "    \n",
    "    axes[idx].hist(scores, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(f'Query {idx+1}\\n{query[:30]}...', fontsize=10)\n",
    "    axes[idx].set_xlabel('Score')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].axvline(0.5, color='red', linestyle='--', label='Good threshold')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/score_distributions.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Saved to reports/figures/score_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: AnÃ¡lisis de features mÃ¡s comunes\n",
    "all_features = {}\n",
    "for analysis in analyses:\n",
    "    for feat in analysis.detected_features:\n",
    "        if feat.confidence >= 0.5:\n",
    "            all_features[feat.name] = all_features.get(feat.name, 0) + 1\n",
    "\n",
    "# Top 20 features\n",
    "top_features = sorted(all_features.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "features, counts = zip(*top_features)\n",
    "plt.barh(features, counts)\n",
    "plt.xlabel('Count')\n",
    "plt.title('Top 20 Most Common Features Detected')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/common_features.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Most common features:\")\n",
    "for feat, count in top_features[:10]:\n",
    "    print(f\"   {feat}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748db6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Matriz de correlaciÃ³n Query-Property\n",
    "# Â¿QuÃ© queries matchean mejor?\n",
    "\n",
    "query_scores = []\n",
    "for query, matches in results_by_query.items():\n",
    "    avg_score = sum(m.final_score for m in matches) / len(matches)\n",
    "    top5_avg = sum(m.final_score for m in matches[:5]) / 5\n",
    "    good_matches = sum(1 for m in matches if m.final_score >= 0.5)\n",
    "    \n",
    "    query_scores.append({\n",
    "        'query': query[:30],\n",
    "        'avg_score': avg_score,\n",
    "        'top5_avg': top5_avg,\n",
    "        'good_matches': good_matches\n",
    "    })\n",
    "\n",
    "df_queries = pd.DataFrame(query_scores)\n",
    "print(df_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e08eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d864d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9afdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed8433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ad1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
